{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jakub Zaręba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Celem projektu jest przewidywanie czasu okrążenia kierowcy F1 w wyścigu. Modele mają dostęp do następujących cech (10 cech), za pomocą których muszą podać czas okrążenia opisanego tymi cechami. Lista cech:\n",
    "- identyfikator wyścigu (raceId)\n",
    "- identyfikator kierowcy (driverId)\n",
    "- numer aktualnego okrążenia, liczone od startu wyścigu 1 okrążenie=start (lap)\n",
    "- aktualna pozycja kierowcy (position)\n",
    "- najlepszy czas uzyskany w kwalifikacjach przez kierowcę (bestQualiTime)\n",
    "- pozycja startowa kierowcy (grid)\n",
    "- tego czy został wezwany na pitstop (isPitStop) -> jeżeli 1 oznacza to, że albo opony są już na skraju wytrzymałości lub doszło do uszkodzeń w bolidzie.\n",
    "- identyfikator toru (circuitId)\n",
    "- tego czy jest to okrążenie wyjazdowe z pitstopu (isOutLap) -> jeżeli 1, to kierowca w pewnym momencie alei serwisowej przekroczy linię mety będąc jeszcze w strefie ograniczenia prędkości oraz po wyjeździe jego opony wymagają \"dogrzania\", czas 1.  okrążenia po zjeździe na pewno będzie gorszy <br/><br/> Wykorzystane przeze mnie dane pochodzą ze strony kaggle.com [źródło](https://www.kaggle.com/datasets/rohanrao/formula-1-world-championship-1950-2020/). Jest to kompletny zbiór danych związany z Formułą 1, zawierający wszystkie możliwe informacje (wszystkie okrążenia, kierowcy, itd.) od 1950r. do 2024r."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Przygotowanie danych\n",
    "Dane znajdują się w osobnych plikach, najpierw połączę je w jeden dataframe biblioteki pandas oraz pozbędę się niepotrzebnych dla modeli informacji. Przekształcę niektóre dane, by uzyskać dostęp do nowych cech, które mogą być przydatne dla modeli."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Funkcja konwertująca czas w formacie X:XX.XXXX na minuty\n",
    "def convert_time_to_min(time):\n",
    "    try:\n",
    "        time=time.replace(\".\",\":\").split(\":\")\n",
    "        time_min=int(time[0])+int(time[1])/60+int(time[2])/60000\n",
    "    except Exception as e:\n",
    "        time_min=pd.NA\n",
    "    return time_min\n",
    "\n",
    "def read_data():\n",
    "    lap_times=pd.read_csv(\"data/lap_times.csv\")\n",
    "    # Kolumna time zawiera czas w formacie X:XX.XXXX,\n",
    "    # dane zawierają kolumnę milliseconds, która nie wymaga konwersji\n",
    "    lap_times=lap_times.drop(\"time\",axis=1)\n",
    "    pit_stops=pd.read_csv(\"data/pit_stops.csv\")\n",
    "    # Porzucenie niepotrzebnych kolumn\n",
    "    pit_stops=pit_stops.drop([\"time\",\"duration\",\"milliseconds\"],axis=1)\n",
    "    # Połączenie danych o czasach okrążeń z danymi o pit stopach (z tego\n",
    "    # będzie można ustalić czy dane okrążenie było zakończone zjazdem do boksu)\n",
    "    data=lap_times.merge(pit_stops,on=[\"raceId\",\"driverId\",\"lap\"],how=\"left\")\n",
    "    # Na tym etapie, możemy ręcznie narzucić pewne wymogi co do danych,\n",
    "    # dzięki \"niezmienności\" pewnych kwestii w F1\n",
    "    # Np. Najszybsze okrążenie w historii F1 to trochę ok. 53s , więc\n",
    "    # usunę okrążenia, które trwały mniej niż 50s (50000 milisekund) oraz te, które trwały więcej niż 140s (120000 milisekund)\n",
    "    data=data[(data[\"milliseconds\"]>50000)]\n",
    "    data=data[(data[\"milliseconds\"]<140000)]\n",
    "\n",
    "    # W miejscu NaN w kolumnie stop (NaN powstały w wyniku operacji merge),\n",
    "    # wstawiamy 0 (oznacza to, że kierowca nie zjeżdżał do boksu),\n",
    "    # każda inna wartość oznacza zjazd do boksu\n",
    "    data[\"stop\"]=data[\"stop\"].fillna(0)\n",
    "    data[\"stop\"]=data[\"stop\"].apply(lambda x: 1 if x!=0 else 0)\n",
    "    data=data.rename(columns={\"stop\":\"isPitStop\"})\n",
    "    \n",
    "    # Ponowna operacja merge z danymi odnośnie pit stopów, by dodać kolumnę\n",
    "    # is_out_lap, która będzie informować czy dane okrążenie było okrążeniem wyjazdowym\n",
    "    # z boksu (kierowca opuszcza boks)\n",
    "    pit_stops=pit_stops.drop(\"stop\",axis=1)\n",
    "    data=data.merge(pit_stops,on=[\"raceId\",\"driverId\"],how=\"left\")\n",
    "    data.rename(columns={\"lap_x\":\"currentLap\",\"lap_y\":\"boxLap\"},inplace=True)\n",
    "    # Jeżeli NaN, kierowca nie zjechał już do końca trwania wyścigu\n",
    "    # (albo go nie ukończył albo nie zjeżdżał do boksu)\n",
    "    data[\"boxLap\"]=data[\"boxLap\"].fillna(0)\n",
    "    data=data.sort_values(\"boxLap\",ascending=False).drop_duplicates(subset=[\"raceId\",\"driverId\",\"currentLap\",\"milliseconds\"],keep=\"first\")\n",
    "    data=data.reset_index(drop=True)\n",
    "    # Initializacja kolumny isOutLap\n",
    "    data[\"isOutLap\"]=0\n",
    "    data[\"isOutLap\"] = data.apply(lambda row: 1 if row[\"currentLap\"] + 1 == row[\"boxLap\"] else 0, axis=1)\n",
    "    data.drop(\"boxLap\",axis=1,inplace=True)\n",
    "    \n",
    "    # Operacja merge z danymi odnośnie końcowych rezultatów\n",
    "    results=pd.read_csv(\"data/results.csv\")\n",
    "    # Porzucenie niepotrzebnych kolumn\n",
    "    results=results[[\"raceId\",\"driverId\",\"constructorId\",\"grid\"]]\n",
    "    data=data.merge(results,on=[\"raceId\",\"driverId\"],how=\"left\")\n",
    "    \n",
    "    # Operacja merge z danymi odnośnie kwalifikacji\n",
    "    quali=pd.read_csv(\"data/qualifying.csv\")\n",
    "    quali=quali[[\"raceId\",\"driverId\",\"q1\",\"q2\",\"q3\"]]\n",
    "    # Zmiana czasu z formatu X:XX.XXXX na czas w minutach\n",
    "    quali[\"q1\"]=quali[\"q1\"].apply(lambda x: convert_time_to_min(x))\n",
    "    quali[\"q2\"]=quali[\"q2\"].apply(lambda x: convert_time_to_min(x))\n",
    "    quali[\"q3\"]=quali[\"q3\"].apply(lambda x: convert_time_to_min(x))\n",
    "    # Obliczenie najlepszego czasu kwalifikacji (najmniejszy czas z q1,q2,q3 lub jedyny lub 0)\n",
    "    quali[\"bestQualiTime\"]=quali[[\"q1\",\"q2\",\"q3\"]].min(axis=1)\n",
    "    quali[\"bestQualiTime\"] = quali[[\"q1\", \"q2\", \"q3\"]].min(axis=1,skipna=True)\n",
    "    # Porzucenie niepotrzebnych kolumn\n",
    "    quali=quali.drop([\"q1\",\"q2\",\"q3\"],axis=1)\n",
    "    data=data.merge(quali,on=[\"raceId\",\"driverId\"],how=\"left\")\n",
    "    data[\"bestQualiTime\"] = data[\"bestQualiTime\"].astype(float).fillna(0)\n",
    "    \n",
    "    # Odrzucenie rzędów z brakującymi danymi odnośnie czasu kwalifikacji\n",
    "    data=data[data[\"bestQualiTime\"]!=0]\n",
    "    \n",
    "    # Operacja merge z danymi odnośnie toru\n",
    "    races=pd.read_csv(\"data/races.csv\")\n",
    "    races=races[[\"raceId\",\"circuitId\"]]\n",
    "    data=data.merge(races,on=\"raceId\",how=\"left\")\n",
    "\n",
    "    data[\"time\"]=data[\"milliseconds\"].apply(lambda x: x/60000)\n",
    "    \n",
    "    # Odrzucenie obserwacji odstających\n",
    "    # W F1 czas pierwszego okrążenia zawsze jest wolniejszy od reszty \n",
    "    # (kierowcy startują z miejsca)\n",
    "    \n",
    "    data=data[data[\"currentLap\"]!=1]\n",
    "    return data\n",
    "\n",
    "data=read_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Zmiana kolejności kolumn dla czytelności\n",
    "data=data[[\n",
    "        \"raceId\",\n",
    "        \"circuitId\",\n",
    "        \"driverId\",\n",
    "        \"constructorId\",\n",
    "        \"grid\",\n",
    "        \"currentLap\",\n",
    "        \"position\",\n",
    "        \"isPitStop\",\n",
    "        \"isOutLap\",\n",
    "        \"bestQualiTime\",\n",
    "        \"time\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   raceId  circuitId  driverId  constructorId  grid  currentLap  position  \\\n",
      "0    1046          3       847            131     2           3         1   \n",
      "2    1046          3       847            131     2           2         1   \n",
      "3    1046          3       847            131     2           7         1   \n",
      "4    1046          3       847            131     2           6         1   \n",
      "5    1046          3       847            131     2          52         1   \n",
      "\n",
      "   isPitStop  isOutLap  bestQualiTime      time  \n",
      "0          0         0        0.89005  1.497167  \n",
      "2          0         0        0.89005  1.640350  \n",
      "3          0         0        0.89005  0.969333  \n",
      "4          0         0        0.89005  1.478300  \n",
      "5          0         0        0.89005  0.951867  \n"
     ]
    }
   ],
   "source": [
    "print(data[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ilość obserwacji: 464089\n"
     ]
    }
   ],
   "source": [
    "print(\"Ilość obserwacji:\",data.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Dalszy preprocessing danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data,test_data=train_test_split(data,test_size=0.2,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Skalowanie danych które zostaną wykorzystane w niektórych modelach. Zastosowałem skalowanie tylko dla kolumn związanych z czasem przejazdu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "columns_names_to_scale=[\"bestQualiTime\",\"time\"]\n",
    "scaler=StandardScaler()\n",
    "columns_to_scale=train_data[columns_names_to_scale]\n",
    "scaler.fit(columns_to_scale)\n",
    "train_data_scaled=train_data.copy()\n",
    "test_data_scaled=test_data.copy()\n",
    "train_data_scaled[columns_names_to_scale]=scaler.transform(columns_to_scale)\n",
    "test_data_scaled[columns_names_to_scale]=scaler.transform(test_data[columns_names_to_scale])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Wyciągnięcie\" jednej obserwacji w celu prezentacji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     raceId  circuitId  driverId  constructorId  grid  currentLap  position  \\\n",
      "859    1107         70       830              9     1          33         2   \n",
      "\n",
      "     isPitStop  isOutLap  bestQualiTime      time  \n",
      "859          0         0        1.07318  1.160517  \n"
     ]
    }
   ],
   "source": [
    "index_to_pick=859\n",
    "example=train_data.loc[[859]]\n",
    "train_data=train_data.drop(859)\n",
    "print(example)\n",
    "example_X=example.drop([\"time\"],axis=1)\n",
    "example_y=example[\"time\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Podział na \"X\" i \"y\" danych bez skalowania i ze skalowaniem.\n",
    "\n",
    "X_train=train_data.drop(\"time\",axis=1)\n",
    "y_train=train_data[\"time\"]\n",
    "X_test=test_data.drop(\"time\",axis=1)\n",
    "y_test=test_data[\"time\"]\n",
    "\n",
    "X_train_scaled=train_data_scaled.drop(\"time\",axis=1)\n",
    "y_train_scaled=train_data_scaled[\"time\"]\n",
    "X_test_scaled=test_data_scaled.drop(\"time\",axis=1)\n",
    "y_test_scaled=test_data_scaled[\"time\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funkcja wyświetlająca w \"ładniejszy\" sposób wartości metryk RMSE oraz MAE dla modeli wykorzystywanych poniżej."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import root_mean_squared_error\n",
    "from sklearn.metrics import median_absolute_error\n",
    "def print_metrics(y_true,y_pred,model_name=None):\n",
    "    mse=root_mean_squared_error(y_true,y_pred)\n",
    "    mae=median_absolute_error(y_true,y_pred)\n",
    "    print(f\"Model: {model_name}\\nRMSE: {mse:.5f}\\nMAE score: {mae:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funkcja wyświetlająca czas rzeczywisty i przewidywany dla 1 przykładu "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_example(model):\n",
    "    prediction=model.predict(example_X)\n",
    "    print(f\"\\nResult for example\\nReal time: {example_y.values[0]}, predicted time: {prediction[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Modele"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Model zwykłej regresji liniowej."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Linear Regression\n",
      "RMSE: 0.14161\n",
      "MAE score: 0.04616\n",
      "\n",
      "Result for example\n",
      "Real time: 1.1605166666666666, predicted time: 1.2237933111506445\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "model=LinearRegression()\n",
    "model.fit(X_train,y_train)\n",
    "y_pred=model.predict(X_test)\n",
    "print_metrics(y_test,y_pred,model_name=\"Linear Regression\")\n",
    "\n",
    "print_example(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Model regresji liniowej z przeskalowanymi danymi dotyczących czasu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Linear Regression bestQualiTime and time scaled with StandardScaler\n",
      "RMSE: 0.62443\n",
      "MAE score: 0.20353\n",
      "\n",
      "Result for example\n",
      "Real time: 1.1605166666666666, predicted time: 0.7665661040357635\n"
     ]
    }
   ],
   "source": [
    "model=LinearRegression()\n",
    "model.fit(X_train_scaled,y_train_scaled)\n",
    "y_pred=model.predict(X_test_scaled)\n",
    "print_metrics(y_test_scaled,y_pred,model_name=\"Linear Regression bestQualiTime and time scaled with StandardScaler\")\n",
    "\n",
    "print_example(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Model z regularyzacją z wykorzystaniem klasy Ridge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Ridge with lambda=3.3\n",
      "RMSE: 0.14161\n",
      "MAE score: 0.04618\n",
      "\n",
      "Result for example\n",
      "Real time: 1.1605166666666666, predicted time: 1.223861427773873\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "# Wartość alpha została podana po prostu jako przykład\n",
    "model=Ridge(alpha=3.3)\n",
    "model.fit(X_train,y_train)\n",
    "y_pred=model.predict(X_test)\n",
    "print_metrics(y_test,y_pred,model_name=\"Ridge with lambda=3.3\")\n",
    "\n",
    "print_example(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Model z regularyzacją z wykorzystaniem Lasso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Lasso with lambda=0.1\n",
      "RMSE: 0.21861\n",
      "MAE score: 0.15625\n",
      "\n",
      "Result for example\n",
      "Real time: 1.1605166666666666, predicted time: 1.5406024100748354\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "# Wartość alpha została podana po prostu jako przykład\n",
    "model=Lasso(alpha=0.1)\n",
    "model.fit(X_train,y_train)\n",
    "y_pred=model.predict(X_test)\n",
    "print_metrics(y_test,y_pred,model_name=\"Lasso with lambda=0.1\")\n",
    "\n",
    "print_example(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Model lasu losowego dla problemu regresji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Random Forest with 50 estimators and max depth 30\n",
      "RMSE: 0.07256\n",
      "MAE score: 0.00802\n",
      "\n",
      "Result for example\n",
      "Real time: 1.1605166666666666, predicted time: 1.161123666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "model=RandomForestRegressor(n_estimators=50,max_depth=30)\n",
    "model.fit(X_train,y_train)\n",
    "y_pred=model.predict(X_test)\n",
    "print_metrics(y_test,y_pred,model_name=\"Random Forest with 50 estimators and max depth 30\")\n",
    "\n",
    "print_example(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Model sieci neuronowej w PyTorch'u\n",
    "\n",
    "**Budowa sieci**:\n",
    "- warstwa droput z domyślnym prawdopodobieństwem wyzerowania 30% (wraz z eksperymentami zmniejszyłem ją do 10%)\n",
    "- warstwa liniowa o wymiarach: rozmiaru danych wejściowych na wejściu tej warstwy i 64 na wyjściu\n",
    "- warstwa liniowa o wymiarach: 64 na wejściu, 32 na wyjściu\n",
    "- warstwa liniowa o wymiarach: 32 na wejśćiu, 1 na wyjściu\\\n",
    "Funkcje aktywacji 2 pierwszych warstw liniowych to *ReLU*.\\\n",
    "Wykorzystywany optymalizator to *Adam*.\\\n",
    "Funkcją błędu jest *RMSE*.\\\n",
    "Zastosowane zostały również następujące parametry:\n",
    "- rozmiar batcha to **64**\n",
    "- współczynnik uczenia to **0.001** (testowałem różne wartości, ta uzyskiwała najlepsze wyniki)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "X_train_tensor=torch.tensor(X_train.values).float()\n",
    "y_train_tensor=torch.tensor(y_train.values).float()\n",
    "\n",
    "X_test_tensor=torch.tensor(X_test.values).float()\n",
    "y_test_tensor=torch.tensor(y_test.values).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Model sieci neuronowej\n",
    "\n",
    "class F1LapTimePredictionModel(nn.Module):\n",
    "    def __init__(self, input_dim, dropout_rate=0.3):\n",
    "        super(F1LapTimePredictionModel, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout_rate)\n",
    "        self.fc1 = nn.Linear(input_dim, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        output = self.fc3(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Epoch 1/20, Loss: 5.48503\n",
      "Epoch 1/20, Loss: 0.45204\n",
      "End of epoch 1/20, Loss: 0.39097\n",
      "Epoch 2/20, Loss: 0.30533\n",
      "Epoch 2/20, Loss: 0.23990\n",
      "End of epoch 2/20, Loss: 0.26069\n",
      "Epoch 3/20, Loss: 0.28529\n",
      "Epoch 3/20, Loss: 0.24109\n",
      "End of epoch 3/20, Loss: 0.23501\n",
      "Epoch 4/20, Loss: 0.27980\n",
      "Epoch 4/20, Loss: 0.22151\n",
      "End of epoch 4/20, Loss: 0.21578\n",
      "Epoch 5/20, Loss: 0.23460\n",
      "Epoch 5/20, Loss: 0.18890\n",
      "End of epoch 5/20, Loss: 0.20089\n",
      "Epoch 6/20, Loss: 0.21524\n",
      "Epoch 6/20, Loss: 0.19374\n",
      "End of epoch 6/20, Loss: 0.18770\n",
      "Epoch 7/20, Loss: 0.17945\n",
      "Epoch 7/20, Loss: 0.19859\n",
      "End of epoch 7/20, Loss: 0.18137\n",
      "Epoch 8/20, Loss: 0.11339\n",
      "Epoch 8/20, Loss: 0.18783\n",
      "End of epoch 8/20, Loss: 0.17898\n",
      "Epoch 9/20, Loss: 0.17368\n",
      "Epoch 9/20, Loss: 0.16277\n",
      "End of epoch 9/20, Loss: 0.17741\n",
      "Epoch 10/20, Loss: 0.16417\n",
      "Epoch 10/20, Loss: 0.17227\n",
      "End of epoch 10/20, Loss: 0.17602\n",
      "Epoch 11/20, Loss: 0.13541\n",
      "Epoch 11/20, Loss: 0.18049\n",
      "End of epoch 11/20, Loss: 0.17499\n",
      "Epoch 12/20, Loss: 0.14092\n",
      "Epoch 12/20, Loss: 0.12476\n",
      "End of epoch 12/20, Loss: 0.17455\n",
      "Epoch 13/20, Loss: 0.16913\n",
      "Epoch 13/20, Loss: 0.15732\n",
      "End of epoch 13/20, Loss: 0.17404\n",
      "Epoch 14/20, Loss: 0.14239\n",
      "Epoch 14/20, Loss: 0.14991\n",
      "End of epoch 14/20, Loss: 0.17335\n",
      "Epoch 15/20, Loss: 0.15639\n",
      "Epoch 15/20, Loss: 0.14195\n",
      "End of epoch 15/20, Loss: 0.17272\n",
      "Epoch 16/20, Loss: 0.21717\n",
      "Epoch 16/20, Loss: 0.13675\n",
      "End of epoch 16/20, Loss: 0.17256\n",
      "Epoch 17/20, Loss: 0.19171\n",
      "Epoch 17/20, Loss: 0.16818\n",
      "End of epoch 17/20, Loss: 0.17193\n",
      "Epoch 18/20, Loss: 0.17299\n",
      "Epoch 18/20, Loss: 0.14678\n",
      "End of epoch 18/20, Loss: 0.17198\n",
      "Epoch 19/20, Loss: 0.17325\n",
      "Epoch 19/20, Loss: 0.15557\n",
      "End of epoch 19/20, Loss: 0.17157\n",
      "Epoch 20/20, Loss: 0.13177\n",
      "Epoch 20/20, Loss: 0.13799\n",
      "End of epoch 20/20, Loss: 0.17146\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Parametry trenowania\n",
    "\n",
    "learning_rate = 0.001\n",
    "epochs = 20\n",
    "batch_size = 64\n",
    "log_interval = 5000  \n",
    "\n",
    "input_dim = X_train_tensor.shape[1]\n",
    "model = F1LapTimePredictionModel(input_dim=input_dim, dropout_rate=0.3)\n",
    "model.to(device)\n",
    "\n",
    "# Z powodu braku implementacji RMSE w PyTorch, musiałem zastosować pewien \"trick\"\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(epochs):\n",
    "    epoch_loss = 0.0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        predictions = model(data)\n",
    "        # Tutaj wspomniany wcześniej \"trick\", obliczam RMSE z MSE, RMSE = sqrt(MSE)\n",
    "        loss = torch.sqrt(criterion(predictions.squeeze(), target))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss.item():.5f}\")\n",
    "    avg_epoch_loss = epoch_loss / len(train_loader)\n",
    "    print(f\"End of epoch {epoch+1}/{epochs}, Loss: {avg_epoch_loss:.5f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ewaluacja modelu sieci neuronowej"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss RMSE: 0.2920, MAE Score: 0.2362\n",
      "Example prediction\n",
      "Real time: 1.1605166666666666, predicted time: 1.2433815002441406\n"
     ]
    }
   ],
   "source": [
    "test_loss_rmse = 0.0\n",
    "test_loss_mae = 0.0\n",
    "\n",
    "model.eval()\n",
    "mae_loss = nn.L1Loss()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        test_predictions = model(data)\n",
    "        mse_loss = criterion(test_predictions.squeeze(), target)\n",
    "        rmse_loss = torch.sqrt(mse_loss)\n",
    "        test_loss_rmse += rmse_loss.item()\n",
    "\n",
    "        mae = mae_loss(test_predictions.squeeze(), target)\n",
    "        test_loss_mae += mae.item()\n",
    "\n",
    "avg_test_loss_rmse = test_loss_rmse / len(test_loader)\n",
    "avg_test_loss_mae = test_loss_mae / len(test_loader)\n",
    "\n",
    "print(f\"Test Loss RMSE: {avg_test_loss_rmse:.4f}, MAE Score: {avg_test_loss_mae:.4f}\")\n",
    "\n",
    "print(\"Example prediction\")\n",
    "example_X_tensor = torch.tensor(example_X.values).float()\n",
    "example_y_tensor = torch.tensor(example_y.values).float()\n",
    "example_X_tensor = example_X_tensor.to(device)\n",
    "example_y_tensor = example_y_tensor.to(device)\n",
    "example_prediction = model(example_X_tensor)\n",
    "print(f\"Real time: {example_y.values[0]}, predicted time: {example_prediction.item()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
